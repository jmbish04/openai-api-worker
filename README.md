# OpenAI-Compatible API Worker

A Cloudflare Worker that exposes Cloudflare AI models through an OpenAI-compatible API interface with built-in documentation and API specification.

## ‚ú® Features

- ‚úÖ **OpenAI API-compatible endpoints** (`/v1/chat/completions`, `/v1/models`, `/v1/completions`)
- ‚úÖ **Static asset hosting** - Landing page and OpenAPI spec served via Cloudflare Assets
- ‚úÖ **Built-in documentation** - Beautiful interactive documentation at `/`
- ‚úÖ **OpenAPI specification** - Complete API documentation at `/openapi.json`
- ‚úÖ **Multi-modal support** - Text generation and image recognition
- ‚úÖ **Streaming responses** - Real-time response streaming
- ‚úÖ **Multiple model support** - Primary and backup models with automatic fallback
- ‚úÖ **CORS support** - Ready for web applications
- ‚úÖ **Authentication** - API key-based security
- ‚úÖ **Health monitoring** - Built-in health check endpoint

## üìÅ Project Structure

```
openai-api-worker/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ index.js           # Main worker with OpenAI API compatibility
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ index.html         # Interactive documentation landing page
‚îÇ   ‚îî‚îÄ‚îÄ openapi.json       # Complete OpenAPI 3.0 specification
‚îú‚îÄ‚îÄ .dev.vars              # Development environment variables
‚îú‚îÄ‚îÄ .gitignore             # Git ignore rules
‚îú‚îÄ‚îÄ README.md              # Complete documentation
‚îú‚îÄ‚îÄ deploy.sh              # Deployment script
‚îú‚îÄ‚îÄ package.json           # NPM configuration
‚îú‚îÄ‚îÄ test.sh                # API testing script
‚îî‚îÄ‚îÄ wrangler.toml          # Cloudflare Worker config with ASSETS binding
```

## ü§ñ Default Models

- **Primary**: `@cf/meta/llama-4-scout-17b-16e-instruct`
- **Backup**: `@cf/openai/gpt-oss-120b`

## üöÄ Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Environment Variables

#### Development (.dev.vars)
```bash
# Set your custom worker API key for local development
WORKER_API_KEY=your-custom-worker-api-key-here
```

#### Production
```bash
# Deploy the worker
npm run deploy
# or
./deploy.sh

# Set the worker API key as a secret (first time only)
wrangler secret put WORKER_API_KEY
```

### 3. Deploy

#### Development
```bash
npm run dev
```
Visit http://localhost:8787 to see the documentation

#### Production
```bash
npm run deploy
```

## üîó API Endpoints

### Public Endpoints (No Authentication)

| Endpoint | Method | Description |
|----------|---------|-------------|
| `/` | GET | Interactive documentation landing page |
| `/openapi.json` | GET | Complete OpenAPI 3.0 specification |
| `/health` | GET | Service health status |

### API Endpoints (Require Authentication)

| Endpoint | Method | Description |
|----------|---------|-------------|
| `/v1/chat/completions` | POST | Create chat completions (streaming & non-streaming) |
| `/v1/models` | GET | List available models |
| `/v1/completions` | POST | Legacy completion endpoint |

## üìñ Usage Examples

### Authentication

Include your worker API key in the Authorization header:

```bash
Authorization: Bearer your-worker-api-key-here
```

### Chat Completions

```bash
curl -X POST https://your-worker.workers.dev/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer your-worker-api-key" \\
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "max_tokens": 100,
    "temperature": 0.7
  }'
```

### With Image Recognition

```bash
curl -X POST https://your-worker.workers.dev/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer your-worker-api-key" \\
  -d '{
    "model": "gpt-4",
    "messages": [
      {
        "role": "user",
        "content": [
          {"type": "text", "text": "What do you see in this image?"},
          {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}}
        ]
      }
    ]
  }'
```

### Streaming Response

```bash
curl -X POST https://your-worker.workers.dev/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer your-worker-api-key" \\
  -d '{
    "model": "gpt-4",
    "messages": [{"role": "user", "content": "Tell me a story"}],
    "stream": true
  }'
```

### JavaScript/Node.js

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer your-worker-api-key'
  },
  body: JSON.stringify({
    model: 'gpt-4',
    messages: [
      { role: 'user', content: 'Explain quantum computing' }
    ],
    max_tokens: 500,
    temperature: 0.7
  })
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

### Python

```python
import requests

response = requests.post(
    'https://your-worker.workers.dev/v1/chat/completions',
    headers={
        'Content-Type': 'application/json',
        'Authorization': 'Bearer your-worker-api-key'
    },
    json={
        'model': 'gpt-4',
        'messages': [
            {'role': 'user', 'content': 'Explain quantum computing'}
        ],
        'max_tokens': 500,
        'temperature': 0.7
    }
)

print(response.json()['choices'][0]['message']['content'])
```

## üîÑ OpenAI Model Mapping

The worker maps OpenAI model names to Cloudflare models:

- `gpt-4` ‚Üí `@cf/meta/llama-4-scout-17b-16e-instruct`
- `gpt-4-turbo` ‚Üí `@cf/meta/llama-4-scout-17b-16e-instruct`
- `gpt-4o` ‚Üí `@cf/meta/llama-4-scout-17b-16e-instruct`
- `gpt-3.5-turbo` ‚Üí `@cf/openai/gpt-oss-120b`
- `gpt-4o-mini` ‚Üí `@cf/openai/gpt-oss-120b`

You can also use Cloudflare model names directly.

## ‚öôÔ∏è Configuration

### Environment Variables

- `DEFAULT_MODEL`: Primary model to use (default: `@cf/meta/llama-4-scout-17b-16e-instruct`)
- `BACKUP_MODEL`: Fallback model (default: `@cf/openai/gpt-oss-120b`)
- `WORKER_API_KEY`: Custom API key for authentication (set as secret)

### Model Fallback

If the primary model fails, the worker automatically tries the backup model.

## üîç Testing

Run the comprehensive test suite:

```bash
# Test local development server
./test.sh

# Test deployed worker
./test.sh https://your-worker.workers.dev your-worker-api-key
```

The test script will verify:
- Landing page accessibility
- OpenAPI specification
- Health check endpoint
- Model listing
- Chat completions (streaming and non-streaming)
- Authentication
- Error handling

## üìä Monitoring & Debugging

### Viewing Logs

```bash
# View live logs
npm run logs
# or
./logs.sh

# Alternative: direct wrangler command
npm run tail
# or
wrangler tail --format=pretty
```

### Debug Logging

The worker includes comprehensive debug logging:

- **Development**: Debug logging is enabled by default (`DEBUG_LOGGING=true`)
- **Production**: Debug logging is disabled for performance (`DEBUG_LOGGING=false`)
- **Authentication**: Logs API key validation attempts  
- **AI Requests**: Tracks model selection and API calls
- **Errors**: Detailed error logging with stack traces

### Health Check

```bash
curl https://your-worker.workers.dev/health
```

Returns:
```json
{
  "status": "healthy",
  "service": "openai-api-worker",
  "timestamp": "2024-09-15T10:30:00.000Z",
  "version": "1.0.0"
}
```

### Error Handling

The API returns proper HTTP status codes and error messages:

- `200`: Success
- `400`: Bad request (invalid parameters)
- `401`: Invalid or missing API key
- `404`: Endpoint not found
- `500`: Internal server error

Example error response:
```json
{
  "error": {
    "message": "Invalid API key",
    "type": "invalid_request_error"
  }
}
```

## üõ† Development

### Local Development

```bash
# Start development server
npm run dev

# Test the API
curl -X POST http://localhost:8787/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer test-key" \\
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello!"}]}'
```

### Deployment

```bash
# Deploy to production
npm run deploy

# View logs
npm run tail

# Quick deploy with secret setup
./deploy.sh
```

## üåê Documentation

Once deployed, your worker provides:

- **Interactive Documentation**: Visit your worker's URL (e.g., `https://your-worker.workers.dev`) for a beautiful, interactive documentation page
- **OpenAPI Specification**: Available at `/openapi.json` for integration with API tools like Postman, Insomnia, or swagger-ui
- **Health Monitoring**: Use `/health` for uptime monitoring and status checks

## üéØ Use Cases

- **Drop-in OpenAI API replacement** - Use existing OpenAI SDKs and tools
- **Edge AI applications** - Low-latency responses via Cloudflare's global network
- **Cost-effective AI** - Leverage Cloudflare's competitive pricing
- **Multi-modal applications** - Build apps that handle both text and images
- **Streaming chat apps** - Real-time conversation interfaces
- **API proxy/gateway** - Add caching, rate limiting, or custom logic

## üîß Advanced Configuration

### Static Asset Management

The worker uses Cloudflare's ASSETS binding to serve static files efficiently:

- **Landing page**: `static/index.html` - Interactive documentation
- **OpenAPI spec**: `static/openapi.json` - Complete API specification
- **Performance**: Static assets are cached at the edge for optimal performance
- **Updates**: Modify files in the `static/` directory and redeploy

### Custom Model Configuration

You can override the default models by setting environment variables:

```toml
# wrangler.toml
[vars]
DEFAULT_MODEL = "@cf/your/custom-model"
BACKUP_MODEL = "@cf/your/backup-model"
```

### CORS Configuration

CORS is enabled by default for all origins. To restrict access, modify the `corsHeaders` in `src/index.js`:

```javascript
const corsHeaders = {
  'Access-Control-Allow-Origin': 'https://your-domain.com',
  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
  'Access-Control-Allow-Headers': 'Content-Type, Authorization',
};
```

## üêõ Troubleshooting

### Common Issues

1. **API Key Authentication Fails**
   - For production, set up the `WORKER_API_KEY` secret: `wrangler secret put WORKER_API_KEY`
   - For development, the API key check is bypassed automatically
   - Check that the Authorization header format is correct: `Bearer <token>`

2. **Model Not Found**
   - Verify the model names in your Cloudflare AI account
   - Check the model mapping in the code

3. **CORS Issues**
   - Ensure CORS headers are properly configured
   - Check that preflight OPTIONS requests are handled

### Debug Mode

Enable debug logging by checking the Cloudflare Workers dashboard logs or using:

```bash
wrangler tail --format=pretty
```

## üìÑ License

MIT License - see LICENSE file for details.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

---

**Powered by [Cloudflare Workers](https://workers.cloudflare.com/) üî•**
