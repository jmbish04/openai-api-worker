{
  "openapi": "3.0.0",
  "info": {
    "title": "OpenAI-Compatible API Worker",
    "description": "A Cloudflare Worker that exposes Cloudflare AI models through an OpenAI-compatible API interface",
    "version": "2.1.0",
    "contact": {
      "name": "API Support"
    },
    "license": {
      "name": "MIT"
    },
    "x-model-capabilities": {
      "description": "Model capabilities by provider. Note: This is a static list that may become outdated. The actual API validation will always use the current model lists from the server.",
      "providers": {
        "openai": {
          "structured_outputs": [
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4o-2024-08-06",
            "gpt-4o-mini-2024-07-18"
          ],
          "function_calling": [
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4o-2024-08-06",
            "gpt-4o-mini-2024-07-18",
            "gpt-4.1",
            "gpt-4.1-mini",
            "gpt-4-0613",
            "gpt-3.5-turbo-0613"
          ],
          "vision": [
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4o-2024-08-06",
            "gpt-4o-mini-2024-07-18",
            "gpt-4.1",
            "gpt-4.1-mini"
          ],
          "recommended": "gpt-4o-mini"
        },
        "gemini": {
          "structured_outputs": [
            "gemini-2.5-pro",
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
            "gemini-2.0-flash-lite"
          ],
          "function_calling": [
            "gemini-2.5-pro",
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
            "gemini-2.0-flash-lite"
          ],
          "vision": [
            "gemini-2.5-pro",
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
            "gemini-2.0-flash-lite"
          ],
          "recommended": "gemini-2.5-flash"
        },
        "cloudflare": {
          "structured_outputs": [
            "@cf/meta/llama-4-scout-17b-16e-instruct",
            "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
            "@cf/meta/llama-3.1-8b-instruct-fp8",
            "@cf/meta/llama-3.1-8b-instruct-awq",
            "@cf/meta/llama-3-8b-instruct-awq",
            "@cf/meta/llama-3-8b-instruct",
            "@cf/meta/llama-3.2-11b-vision-instruct",
            "@cf/meta/llama-3.2-3b-instruct",
            "@cf/meta/llama-3.2-1b-instruct",
            "@cf/mistralai/mistral-small-3.1-24b-instruct",
            "@cf/mistral/mistral-7b-instruct-v0.2-lora",
            "@cf/mistral/mistral-7b-instruct-v0.1",
            "@cf/qwen/qwen2.5-coder-32b-instruct",
            "@cf/qwen/qwen1.5-14b-chat-awq",
            "@cf/qwen/qwen1.5-7b-chat-awq",
            "@cf/qwen/qwen1.5-1.8b-chat",
            "@cf/qwen/qwen1.5-0.5b-chat",
            "@cf/google/gemma-3-12b-it",
            "@cf/google/gemma-7b-it-lora",
            "@cf/google/gemma-2b-it-lora",
            "@cf/openchat/openchat-3.5-0106",
            "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
            "@cf/deepseek-ai/deepseek-math-7b-instruct",
            "@cf/defog/sqlcoder-7b-2"
          ],
          "vision": [
            "@cf/meta/llama-3.2-11b-vision-instruct",
            "@cf/llava-hf/llava-1.5-7b-hf"
          ],
          "reasoning": [
            "@cf/meta/llama-4-scout-17b-16e-instruct",
            "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
            "@cf/deepseek-ai/deepseek-math-7b-instruct"
          ],
          "recommended": "@cf/meta/llama-4-scout-17b-16e-instruct"
        }
      }
    }
  },
  "servers": [
    {
      "url": "https://openai-api-worker.your-subdomain.workers.dev",
      "description": "Production server"
    },
    {
      "url": "http://localhost:8787",
      "description": "Development server"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/": {
      "get": {
        "summary": "Landing page",
        "description": "Returns the API documentation landing page",
        "responses": {
          "200": {
            "description": "HTML landing page",
            "content": {
              "text/html": {
                "schema": {
                  "type": "string"
                }
              }
            }
          }
        }
      }
    },
    "/openapi.json": {
      "get": {
        "summary": "OpenAPI specification",
        "description": "Returns the OpenAPI specification for this API",
        "responses": {
          "200": {
            "description": "OpenAPI specification",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object"
                }
              }
            }
          }
        }
      }
    },
    "/health": {
      "get": {
        "summary": "Health check",
        "description": "Returns the health status of the API",
        "responses": {
          "200": {
            "description": "Health status",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "string",
                      "example": "healthy"
                    },
                    "service": {
                      "type": "string",
                      "example": "openai-api-worker"
                    },
                    "timestamp": {
                      "type": "string",
                      "format": "date-time"
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "/v1/models": {
      "get": {
        "summary": "List available models",
        "description": "Lists the currently available models, and provides basic information about each one",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "responses": {
          "200": {
            "description": "List of available models",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "object": {
                      "type": "string",
                      "example": "list"
                    },
                    "data": {
                      "type": "array",
                      "items": {
                        "$ref": "#/components/schemas/Model"
                      }
                    }
                  }
                }
              }
            }
          },
          "401": {
            "$ref": "#/components/responses/UnauthorizedError"
          }
        }
      }
    },
    "/v1/chat/completions": {
      "post": {
        "summary": "Create chat completion",
        "description": "Creates a model response for the given chat conversation with optional memory support",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Chat completion response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "type": "string",
                  "description": "Server-sent events stream for streaming responses"
                }
              }
            }
          },
          "400": {
            "$ref": "#/components/responses/BadRequestError"
          },
          "401": {
            "$ref": "#/components/responses/UnauthorizedError"
          },
          "500": {
            "$ref": "#/components/responses/InternalServerError"
          }
        }
      }
    },
    "/v1/chat/completions/structured": {
      "post": {
        "summary": "Create structured chat completion",
        "description": "Creates a structured model response with JSON schema validation and optional memory support\n\n**Supported Models for Structured Outputs:**\n- **Openai**: 4 models supported (recommended: `gpt-4o-mini`)\n- **Gemini**: 5 models supported (recommended: `gemini-2.5-flash`)\n- **Cloudflare**: 24 models supported (recommended: `@cf/meta/llama-4-scout-17b-16e-instruct`)\n\n*Note: This is a static list. The actual API validation uses current model lists from the server.*\n\n**Supported Models for Structured Outputs:**\n- **Openai**: 4 models supported (recommended: `gpt-4o-mini`)\n- **Gemini**: 5 models supported (recommended: `gemini-2.5-flash`)\n- **Cloudflare**: 24 models supported (recommended: `@cf/meta/llama-4-scout-17b-16e-instruct`)\n\n*Note: This is a static list. The actual API validation uses current model lists from the server.*\n\n**Supported Models for Structured Outputs:**\n- **Openai**: 4 models supported (recommended: `gpt-4o-mini`)\n- **Gemini**: 5 models supported (recommended: `gemini-2.5-flash`)\n- **Cloudflare**: 24 models supported (recommended: `@cf/meta/llama-4-scout-17b-16e-instruct`)\n\n*Note: This is a static list. The actual API validation uses current model lists from the server.*\n\n**Supported Models for Structured Outputs:**\n- **Openai**: 4 models supported (recommended: `gpt-4o-mini`)\n- **Gemini**: 5 models supported (recommended: `gemini-2.5-flash`)\n- **Cloudflare**: 24 models supported (recommended: `@cf/meta/llama-4-scout-17b-16e-instruct`)\n\n*Note: This is a static list. The actual API validation uses current model lists from the server.*",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/StructuredChatCompletionRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Structured chat completion response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "type": "string",
                  "description": "Server-sent events stream for streaming responses"
                }
              }
            }
          },
          "400": {
            "$ref": "#/components/responses/BadRequestError"
          },
          "401": {
            "$ref": "#/components/responses/UnauthorizedError"
          },
          "500": {
            "$ref": "#/components/responses/InternalServerError"
          }
        }
      }
    },
    "/v1/chat/completions/text": {
      "post": {
        "summary": "Create text chat completion",
        "description": "Creates a text-only model response with optional memory support (no structured output)",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TextChatCompletionRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Text chat completion response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "type": "string",
                  "description": "Server-sent events stream for streaming responses"
                }
              }
            }
          },
          "400": {
            "$ref": "#/components/responses/BadRequestError"
          },
          "401": {
            "$ref": "#/components/responses/UnauthorizedError"
          },
          "500": {
            "$ref": "#/components/responses/InternalServerError"
          }
        }
      }
    },
    "/v1/completions": {
      "post": {
        "summary": "Create completion (legacy)",
        "description": "Creates a completion for the provided prompt and parameters (legacy endpoint)",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CompletionRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Completion response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "$ref": "#/components/responses/BadRequestError"
          },
          "401": {
            "$ref": "#/components/responses/UnauthorizedError"
          },
          "500": {
            "$ref": "#/components/responses/InternalServerError"
          }
        }
      }
    },
    "/v1/completions/withmemory": {
      "post": {
        "summary": "Create completion with memory",
        "description": "Creates a completion with KV-based conversation memory support. Requires memory=true and memory_keyword parameters.",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CompletionWithMemoryRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Completion response with memory context",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "$ref": "#/components/responses/BadRequestError"
          },
          "401": {
            "$ref": "#/components/responses/UnauthorizedError"
          },
          "500": {
            "$ref": "#/components/responses/InternalServerError"
          }
        }
      }
    }
  },
  "components": {
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "API key authentication"
      }
    },
    "schemas": {
      "Model": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "example": "gpt-4"
          },
          "object": {
            "type": "string",
            "example": "model"
          },
          "created": {
            "type": "integer",
            "example": 1677610602
          },
          "owned_by": {
            "type": "string",
            "example": "cloudflare"
          }
        }
      },
      "ChatMessage": {
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "system",
              "user",
              "assistant"
            ],
            "description": "The role of the message author"
          },
          "content": {
            "oneOf": [
              {
                "type": "string",
                "description": "Text content"
              },
              {
                "type": "array",
                "description": "Multimodal content (text + images)",
                "items": {
                  "type": "object",
                  "properties": {
                    "type": {
                      "type": "string",
                      "enum": [
                        "text",
                        "image_url"
                      ]
                    },
                    "text": {
                      "type": "string"
                    },
                    "image_url": {
                      "type": "object",
                      "properties": {
                        "url": {
                          "type": "string",
                          "description": "Image URL or base64 data URL"
                        }
                      }
                    }
                  }
                }
              }
            ]
          }
        }
      },
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Model identifier. Examples: gpt-4o-mini, gemini-2.5-flash, @cf/meta/llama-4-scout-17b-16e-instruct",
            "example": "gpt-4",
            "enum": [
              "gpt-4",
              "gpt-4-turbo",
              "gpt-4o",
              "gpt-4o-mini",
              "gpt-3.5-turbo",
              "@cf/meta/llama-4-scout-17b-16e-instruct",
              "@cf/openai/gpt-oss-120b"
            ],
            "x-examples": [
              {
                "provider": "openai",
                "recommended": "gpt-4o-mini",
                "supported_models": [
                  "gpt-4o",
                  "gpt-4o-mini",
                  "gpt-4o-2024-08-06",
                  "gpt-4o-mini-2024-07-18"
                ]
              },
              {
                "provider": "gemini",
                "recommended": "gemini-2.5-flash",
                "supported_models": [
                  "gemini-2.5-pro",
                  "gemini-2.5-flash",
                  "gemini-2.5-flash-lite",
                  "gemini-2.0-flash",
                  "gemini-2.0-flash-lite"
                ]
              },
              {
                "provider": "cloudflare",
                "recommended": "@cf/meta/llama-4-scout-17b-16e-instruct",
                "supported_models": [
                  "@cf/meta/llama-4-scout-17b-16e-instruct",
                  "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
                  "@cf/meta/llama-3.1-8b-instruct-fp8",
                  "@cf/meta/llama-3.1-8b-instruct-awq",
                  "@cf/meta/llama-3-8b-instruct-awq"
                ]
              }
            ]
          },
          "messages": {
            "type": "array",
            "description": "List of messages comprising the conversation",
            "items": {
              "$ref": "#/components/schemas/ChatMessage"
            }
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 2048,
            "minimum": 1,
            "maximum": 4096
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature between 0 and 2",
            "default": 0.7,
            "minimum": 0,
            "maximum": 2
          },
          "top_p": {
            "type": "number",
            "description": "Nucleus sampling parameter",
            "default": 1,
            "minimum": 0,
            "maximum": 1
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream back partial progress",
            "default": false
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Frequency penalty between -2.0 and 2.0",
            "default": 0,
            "minimum": -2,
            "maximum": 2
          },
          "presence_penalty": {
            "type": "number",
            "description": "Presence penalty between -2.0 and 2.0",
            "default": 0,
            "minimum": -2,
            "maximum": 2
          },
          "memory": {
            "type": "boolean",
            "description": "Enable KV-based conversation memory. When true, memory_keyword is required.",
            "default": false
          },
          "memory_keyword": {
            "type": "string",
            "description": "Keyword for KV memory isolation. Required when memory=true.",
            "example": "user123-session"
          },
          "response_format": {
            "type": "object",
            "description": "Response format configuration",
            "properties": {
              "type": {
                "type": "string",
                "enum": [
                  "text",
                  "json_object",
                  "json_schema"
                ],
                "description": "Type of response format"
              },
              "schema": {
                "type": "object",
                "description": "JSON schema for structured responses (required when type is json_schema)"
              }
            }
          }
        }
      },
      "StructuredChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages",
          "response_format"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Model identifier. Examples: gpt-4o-mini, gemini-2.5-flash, @cf/meta/llama-4-scout-17b-16e-instruct",
            "example": "gpt-4",
            "enum": [
              "gpt-4",
              "gpt-4-turbo",
              "gpt-4o",
              "gpt-4o-mini",
              "gpt-3.5-turbo",
              "@cf/meta/llama-4-scout-17b-16e-instruct",
              "@cf/openai/gpt-oss-120b"
            ],
            "x-examples": [
              {
                "provider": "openai",
                "recommended": "gpt-4o-mini",
                "supported_models": [
                  "gpt-4o",
                  "gpt-4o-mini",
                  "gpt-4o-2024-08-06",
                  "gpt-4o-mini-2024-07-18"
                ]
              },
              {
                "provider": "gemini",
                "recommended": "gemini-2.5-flash",
                "supported_models": [
                  "gemini-2.5-pro",
                  "gemini-2.5-flash",
                  "gemini-2.5-flash-lite",
                  "gemini-2.0-flash",
                  "gemini-2.0-flash-lite"
                ]
              },
              {
                "provider": "cloudflare",
                "recommended": "@cf/meta/llama-4-scout-17b-16e-instruct",
                "supported_models": [
                  "@cf/meta/llama-4-scout-17b-16e-instruct",
                  "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
                  "@cf/meta/llama-3.1-8b-instruct-fp8",
                  "@cf/meta/llama-3.1-8b-instruct-awq",
                  "@cf/meta/llama-3-8b-instruct-awq"
                ]
              }
            ]
          },
          "messages": {
            "type": "array",
            "description": "List of messages comprising the conversation",
            "items": {
              "$ref": "#/components/schemas/ChatMessage"
            }
          },
          "response_format": {
            "type": "object",
            "description": "Response format configuration (required for structured endpoints)",
            "required": [
              "type",
              "schema"
            ],
            "properties": {
              "type": {
                "type": "string",
                "enum": [
                  "json_object",
                  "json_schema"
                ],
                "description": "Type of structured response format"
              },
              "schema": {
                "type": "object",
                "description": "JSON schema for structured responses"
              }
            }
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 2048,
            "minimum": 1,
            "maximum": 4096
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature between 0 and 2",
            "default": 0.7,
            "minimum": 0,
            "maximum": 2
          },
          "top_p": {
            "type": "number",
            "description": "Nucleus sampling parameter",
            "default": 1,
            "minimum": 0,
            "maximum": 1
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream back partial progress",
            "default": false
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Frequency penalty between -2.0 and 2.0",
            "default": 0,
            "minimum": -2,
            "maximum": 2
          },
          "presence_penalty": {
            "type": "number",
            "description": "Presence penalty between -2.0 and 2.0",
            "default": 0,
            "minimum": -2,
            "maximum": 2
          },
          "memory": {
            "type": "boolean",
            "description": "Enable KV-based conversation memory. When true, memory_keyword is required.",
            "default": false
          },
          "memory_keyword": {
            "type": "string",
            "description": "Keyword for KV memory isolation. Required when memory=true.",
            "example": "user123-session"
          }
        }
      },
      "TextChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Model identifier. Examples: gpt-4o-mini, gemini-2.5-flash, @cf/meta/llama-4-scout-17b-16e-instruct",
            "example": "gpt-4",
            "enum": [
              "gpt-4",
              "gpt-4-turbo",
              "gpt-4o",
              "gpt-4o-mini",
              "gpt-3.5-turbo",
              "@cf/meta/llama-4-scout-17b-16e-instruct",
              "@cf/openai/gpt-oss-120b"
            ],
            "x-examples": [
              {
                "provider": "openai",
                "recommended": "gpt-4o-mini",
                "supported_models": [
                  "gpt-4o",
                  "gpt-4o-mini",
                  "gpt-4o-2024-08-06",
                  "gpt-4o-mini-2024-07-18"
                ]
              },
              {
                "provider": "gemini",
                "recommended": "gemini-2.5-flash",
                "supported_models": [
                  "gemini-2.5-pro",
                  "gemini-2.5-flash",
                  "gemini-2.5-flash-lite",
                  "gemini-2.0-flash",
                  "gemini-2.0-flash-lite"
                ]
              },
              {
                "provider": "cloudflare",
                "recommended": "@cf/meta/llama-4-scout-17b-16e-instruct",
                "supported_models": [
                  "@cf/meta/llama-4-scout-17b-16e-instruct",
                  "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
                  "@cf/meta/llama-3.1-8b-instruct-fp8",
                  "@cf/meta/llama-3.1-8b-instruct-awq",
                  "@cf/meta/llama-3-8b-instruct-awq"
                ]
              }
            ]
          },
          "messages": {
            "type": "array",
            "description": "List of messages comprising the conversation",
            "items": {
              "$ref": "#/components/schemas/ChatMessage"
            }
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 2048,
            "minimum": 1,
            "maximum": 4096
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature between 0 and 2",
            "default": 0.7,
            "minimum": 0,
            "maximum": 2
          },
          "top_p": {
            "type": "number",
            "description": "Nucleus sampling parameter",
            "default": 1,
            "minimum": 0,
            "maximum": 1
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream back partial progress",
            "default": false
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Frequency penalty between -2.0 and 2.0",
            "default": 0,
            "minimum": -2,
            "maximum": 2
          },
          "presence_penalty": {
            "type": "number",
            "description": "Presence penalty between -2.0 and 2.0",
            "default": 0,
            "minimum": -2,
            "maximum": 2
          },
          "memory": {
            "type": "boolean",
            "description": "Enable KV-based conversation memory. When true, memory_keyword is required.",
            "default": false
          },
          "memory_keyword": {
            "type": "string",
            "description": "Keyword for KV memory isolation. Required when memory=true.",
            "example": "user123-session"
          }
        }
      },
      "CompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "prompt"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "ID of the model to use",
            "example": "gpt-3.5-turbo"
          },
          "prompt": {
            "type": "string",
            "description": "The prompt to generate completions for"
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 100
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature",
            "default": 0.7
          }
        }
      },
      "CompletionWithMemoryRequest": {
        "type": "object",
        "required": [
          "model",
          "prompt",
          "memory",
          "memory_keyword"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "ID of the model to use",
            "example": "gpt-3.5-turbo"
          },
          "prompt": {
            "type": "string",
            "description": "The prompt to generate completions for"
          },
          "memory": {
            "type": "boolean",
            "description": "Enable KV-based conversation memory (must be true for this endpoint)",
            "const": true
          },
          "memory_keyword": {
            "type": "string",
            "description": "Keyword for KV memory isolation (required for memory-enabled completions)",
            "example": "user123-session"
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 100
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature",
            "default": 0.7
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "example": "chatcmpl-123"
          },
          "object": {
            "type": "string",
            "example": "chat.completion"
          },
          "created": {
            "type": "integer",
            "example": 1677652288
          },
          "model": {
            "type": "string",
            "example": "gpt-4"
          },
          "choices": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "index": {
                  "type": "integer"
                },
                "message": {
                  "$ref": "#/components/schemas/ChatMessage"
                },
                "finish_reason": {
                  "type": "string",
                  "enum": [
                    "stop",
                    "length",
                    "content_filter"
                  ]
                }
              }
            }
          },
          "usage": {
            "type": "object",
            "properties": {
              "prompt_tokens": {
                "type": "integer"
              },
              "completion_tokens": {
                "type": "integer"
              },
              "total_tokens": {
                "type": "integer"
              }
            }
          }
        }
      },
      "Error": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "message": {
                "type": "string"
              },
              "type": {
                "type": "string"
              },
              "code": {
                "type": "string"
              }
            }
          }
        }
      }
    },
    "responses": {
      "UnauthorizedError": {
        "description": "Authentication information is missing or invalid",
        "content": {
          "application/json": {
            "schema": {
              "$ref": "#/components/schemas/Error"
            },
            "example": {
              "error": {
                "message": "Invalid API key",
                "type": "invalid_request_error"
              }
            }
          }
        }
      },
      "BadRequestError": {
        "description": "Bad request",
        "content": {
          "application/json": {
            "schema": {
              "$ref": "#/components/schemas/Error"
            },
            "example": {
              "error": {
                "message": "messages parameter is required and must be an array",
                "type": "invalid_request_error"
              }
            }
          }
        }
      },
      "InternalServerError": {
        "description": "Internal server error",
        "content": {
          "application/json": {
            "schema": {
              "$ref": "#/components/schemas/Error"
            },
            "example": {
              "error": {
                "message": "AI service error",
                "type": "server_error"
              }
            }
          }
        }
      }
    }
  },
  "tags": [
    {
      "name": "Models",
      "description": "List and describe the various models available in the API"
    },
    {
      "name": "Chat",
      "description": "Create chat completions with optional memory support"
    },
    {
      "name": "Structured Chat",
      "description": "Create structured chat completions with JSON schema validation"
    },
    {
      "name": "Text Chat",
      "description": "Create text-only chat completions without structured output"
    },
    {
      "name": "Completions",
      "description": "Create text completions (legacy)"
    },
    {
      "name": "Memory Completions",
      "description": "Create text completions with KV-based conversation memory"
    }
  ]
}